{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c0a747",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from monai.config import print_config\n",
    "from monai.data import DataLoader\n",
    "\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "import random\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "import torchvision\n",
    "import pandas as pd\n",
    "from skimage.metrics import structural_similarity as ssim_fn\n",
    "import wandb\n",
    "\n",
    "\n",
    "from torch import nn\n",
    "\n",
    "\n",
    "from tqdm import trange, tqdm\n",
    "\n",
    "\n",
    "\n",
    "print_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad7be57",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UnifiedBrainDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None, split=\"train\", seed=42):\n",
    "        assert split in [\"train\", \"val\", \"test\"], \"split must be 'train', 'val' or 'test'\"\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.split = split\n",
    "        self.seed = seed\n",
    "        self.samples = self._create_file_pairs()\n",
    "        self._split_dataset()\n",
    "\n",
    "    def _create_file_pairs(self):\n",
    "        t1_dir = os.path.join(self.root_dir, \"t1\")\n",
    "        t2_dir = os.path.join(self.root_dir, \"t2\")\n",
    "\n",
    "        t1_files = set(os.listdir(t1_dir))\n",
    "        t2_files = set(os.listdir(t2_dir))\n",
    "        common_files = list(t1_files.intersection(t2_files))\n",
    "        common_files.sort()\n",
    "\n",
    "        pairs = [(os.path.join(t1_dir, fname), os.path.join(t2_dir, fname)) for fname in common_files]\n",
    "        return pairs\n",
    "\n",
    "    def _split_dataset(self):\n",
    "        random.seed(self.seed)\n",
    "        random.shuffle(self.samples)\n",
    "\n",
    "        n_total = len(self.samples)\n",
    "        n_train = int(n_total * 0.80)\n",
    "        n_val = int(n_total * 0.05)\n",
    "        n_test = n_total - n_train - n_val\n",
    "\n",
    "        if self.split == \"train\":\n",
    "            self.samples = self.samples[:n_train]\n",
    "        elif self.split == \"val\":\n",
    "            self.samples = self.samples[n_train:n_train + n_val]\n",
    "        elif self.split == \"test\":\n",
    "            self.samples = self.samples[n_train + n_val:]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        t1_path, t2_path = self.samples[idx]\n",
    "        t1_image = Image.open(t1_path).convert(\"L\")\n",
    "        t2_image = Image.open(t2_path).convert(\"L\")\n",
    "\n",
    "        if self.transform:\n",
    "            t1_image = self.transform(t1_image)\n",
    "            t2_image = self.transform(t2_image)\n",
    "\n",
    "        return {\n",
    "            \"t1\": t1_image,\n",
    "            \"t2\": t2_image,\n",
    "            \"filename\": os.path.basename(t1_path)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e16622",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATAPATH = DATAPATH = '/home/andrea_moschetto/FlowMatching-MREConversion/data'\n",
    "OUTPUT_DIR = \"/home/andrea_moschetto/FlowMatching-MREConversion/outputs\"\n",
    "CHECKPOINTS_PATH = '/home/andrea_moschetto/FlowMatching-MREConversion/baseline_checkpoints'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68808d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Pad(padding=(5, 3, 5, 3), fill=0),\n",
    "    transforms.ToTensor(),  # Normalize to [0, 1]\n",
    "])\n",
    "BATCH_SIZE = 128\n",
    "NUM_WORKERS = 4\n",
    "train_dataset = UnifiedBrainDataset(root_dir=DATAPATH, transform=transform, split=\"train\")\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, num_workers=NUM_WORKERS, shuffle=True)\n",
    "val_dataset = UnifiedBrainDataset(root_dir=DATAPATH, transform=transform, split=\"val\")\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, num_workers=NUM_WORKERS, shuffle=False)\n",
    "test_dataset = UnifiedBrainDataset(root_dir=DATAPATH, transform=transform, split=\"test\")\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, num_workers=NUM_WORKERS, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a09e806e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "\n",
    "\n",
    "class UnetSkipConnectionBlock2D(nn.Module):\n",
    "    def __init__(self, outer_nc, inner_nc, in_channels=None, submodule=None, outermost=False, innermost=False, norm_layer=nn.InstanceNorm2d, use_dropout=True):\n",
    "        super(UnetSkipConnectionBlock2D, self).__init__()\n",
    "        self.outermost = outermost\n",
    "        if type(norm_layer) == functools.partial:\n",
    "            use_bias = norm_layer.func == nn.InstanceNorm2d\n",
    "        else:\n",
    "            use_bias = norm_layer == nn.InstanceNorm2d\n",
    "        if in_channels is None:\n",
    "            in_channels = outer_nc\n",
    "        downconv = nn.Conv2d(in_channels, inner_nc, kernel_size=4, stride=2, padding=1, bias=use_bias)\n",
    "        downrelu = nn.LeakyReLU(0.2, True)\n",
    "        downnorm = norm_layer(inner_nc)\n",
    "        uprelu = nn.ReLU(True)\n",
    "        upnorm = norm_layer(outer_nc)\n",
    "\n",
    "        if outermost:\n",
    "            upconv = nn.ConvTranspose2d(inner_nc * 2, outer_nc, kernel_size=4, stride=2, padding=1)\n",
    "            down = [downconv]\n",
    "            up = [uprelu, upconv, nn.Tanh()]\n",
    "            model = down + [submodule] + up\n",
    "        elif innermost:\n",
    "            upconv = nn.ConvTranspose2d(inner_nc, outer_nc, kernel_size=4, stride=2, padding=1, bias=use_bias)\n",
    "            down = [downrelu, downconv]\n",
    "            up = [uprelu, upconv, upnorm]\n",
    "            model = down + up\n",
    "        else:\n",
    "            upconv = nn.ConvTranspose2d(inner_nc * 2, outer_nc, kernel_size=4, stride=2, padding=1, bias=use_bias)\n",
    "            down = [downrelu, downconv, downnorm]\n",
    "            up = [uprelu, upconv, upnorm]\n",
    "\n",
    "            if use_dropout:\n",
    "                model = down + [submodule] + up + [nn.Dropout(0.5)]\n",
    "            else:\n",
    "                model = down + [submodule] + up\n",
    "\n",
    "        self.model = nn.Sequential(*model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.outermost:\n",
    "            return self.model(x)\n",
    "        else:   # add skip connections\n",
    "            return torch.cat([x, self.model(x)], 1)\n",
    "        \n",
    "class UNetGenerator2D(nn.Module):\n",
    "    def __init__(self, in_channels=1, out_channels=1, num_downs=7, ngf=64, norm_layer=nn.InstanceNorm2d, use_dropout=True):\n",
    "        super(UNetGenerator2D, self).__init__()\n",
    "\n",
    "        # construct unet structure\n",
    "        unet_block = UnetSkipConnectionBlock2D(ngf * 8, ngf * 8, in_channels=None, submodule=None, norm_layer=norm_layer, innermost=True)  # innermost\n",
    "        for i in range(num_downs - 5): # add intermediate layers with ngf * 8 filters\n",
    "            unet_block = UnetSkipConnectionBlock2D(ngf * 8, ngf * 8, in_channels=None, submodule=unet_block, norm_layer=norm_layer, use_dropout=use_dropout)\n",
    "        unet_block = UnetSkipConnectionBlock2D(ngf * 4, ngf * 8, in_channels=None, submodule=unet_block, norm_layer=norm_layer)\n",
    "        unet_block = UnetSkipConnectionBlock2D(ngf * 2, ngf * 4, in_channels=None, submodule=unet_block, norm_layer=norm_layer)\n",
    "        unet_block = UnetSkipConnectionBlock2D(ngf, ngf * 2, in_channels=None, submodule=unet_block, norm_layer=norm_layer)\n",
    "        self.model = UnetSkipConnectionBlock2D(out_channels, ngf, in_channels=in_channels, submodule=unet_block, outermost=True, norm_layer=norm_layer)\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.model(input)\n",
    "    \n",
    "\n",
    "class NLayerDiscriminator2D(nn.Module):\n",
    "    def __init__(self, input_nc, ndf=64, n_layers=3, norm_layer=nn.InstanceNorm2d):\n",
    "        super(NLayerDiscriminator2D, self).__init__()\n",
    "        if type(norm_layer) == functools.partial:  # no need to use bias as BatchNorm2d has affine parameters\n",
    "            use_bias = norm_layer.func == nn.InstanceNorm2d\n",
    "        else:\n",
    "            use_bias = norm_layer == nn.InstanceNorm2d\n",
    "\n",
    "        kw = 4 # kernel width\n",
    "        padw = 1 # padding width\n",
    "        sequence = [nn.Conv2d(input_nc, ndf, kernel_size=kw, stride=2, padding=padw), nn.LeakyReLU(0.2, True)]\n",
    "        nf_mult = 1\n",
    "        nf_mult_prev = 1\n",
    "        for n in range(1, n_layers):  # gradually increase the number of filters\n",
    "            nf_mult_prev = nf_mult\n",
    "            nf_mult = min(2 ** n, 8)\n",
    "            sequence += [\n",
    "                nn.Conv2d(ndf * nf_mult_prev, ndf * nf_mult, kernel_size=kw, stride=2, padding=padw, bias=use_bias),\n",
    "                norm_layer(ndf * nf_mult),\n",
    "                nn.LeakyReLU(0.2, True)\n",
    "            ]\n",
    "\n",
    "        nf_mult_prev = nf_mult\n",
    "        nf_mult = min(2 ** n_layers, 8)\n",
    "        sequence += [\n",
    "            nn.Conv2d(ndf * nf_mult_prev, ndf * nf_mult, kernel_size=kw, stride=1, padding=padw, bias=use_bias),\n",
    "            norm_layer(ndf * nf_mult),\n",
    "            nn.LeakyReLU(0.2, True)\n",
    "        ]\n",
    "\n",
    "        sequence += [nn.Conv2d(ndf * nf_mult, 1, kernel_size=kw, stride=1, padding=padw)]  # output 1 channel prediction map\n",
    "        self.model = nn.Sequential(*sequence)\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.model(input)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6473504e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def percnorm(arr, lperc=5, uperc=99.5):\n",
    "    \"\"\"\n",
    "    Remove outlier intensities from a brain component,\n",
    "    similar to Tukey's fences method.\n",
    "    \"\"\"\n",
    "    upperbound = np.percentile(arr, uperc)\n",
    "    lowerbound = np.percentile(arr, lperc)\n",
    "    arr[arr > upperbound] = upperbound\n",
    "    arr[arr < lowerbound] = lowerbound\n",
    "    return arr\n",
    "\n",
    "def normalize(img):\n",
    "    # img: [C, H, W]\n",
    "    img = (img - img.min())/ (img.max() - img.min() + 1e-8)\n",
    "    return img\n",
    "\n",
    "def preprocess_image(in_tensor_img):\n",
    "    # tensor_img: [1, H, W]\n",
    "    img_np = in_tensor_img.squeeze(0).cpu().numpy()  # [H, W]\n",
    "    img_np = percnorm(img_np)                     # Percentile-based normalization\n",
    "    out_tensor_image = torch.from_numpy(img_np).unsqueeze(0)  # Back to [1, H, W]\n",
    "    out_tensor_image = normalize(out_tensor_image)            # 0-1 normalization\n",
    "    return out_tensor_image.to(in_tensor_img.device)  # [1, 1, H, W]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53826fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(f'{CHECKPOINTS_PATH}/backups'):\n",
    "    os.makedirs(f'{CHECKPOINTS_PATH}/backups')\n",
    "\n",
    "def get_norm_layer():\n",
    "\n",
    "    norm_layer = functools.partial(nn.InstanceNorm3d, affine=False, track_running_stats=False)\n",
    "\n",
    "    return norm_layer\n",
    "\n",
    "# Initialize weights (optional, often helpful for GANs)\n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        nn.init.constant_(m.bias.data, 0.0)\n",
    "            \n",
    "def train_GAN(netG: UNetGenerator2D, netD: NLayerDiscriminator2D, train_loader: DataLoader, val_loader: DataLoader, project: str, exp_name: str, notes: str, n_epochs: int = 200, n_epochs_decay: int = 100, lr_g: float = 0.0002, lr_d: float = 0.00005, beta1: float = 0.5, lambda_l1: float = 100.0):\n",
    "    with wandb.init(\n",
    "        project=project,\n",
    "        name=exp_name,\n",
    "        notes=notes,\n",
    "        tags=[\"flow\", \"brain\", \"diffusion\"],\n",
    "        config={\n",
    "            'modelG': netG.__class__.__name__,\n",
    "            'modelD': netD.__class__.__name__,\n",
    "            'epochs': n_epochs,\n",
    "            'n_epochs_decay': n_epochs_decay,\n",
    "            'batch_size': train_loader.batch_size,\n",
    "            'num_workers': train_loader.num_workers,\n",
    "            'optimizer': 'Adam',\n",
    "            'learning_rate_g': lr_g,\n",
    "            'learning_rate_d': lr_d,\n",
    "            'beta1': beta1,\n",
    "            'lambda_l1': lambda_l1,\n",
    "            'loss_functions': 'BCEWithLogitsLoss, L1Loss',\n",
    "            'device': str(torch.cuda.get_device_name(0)\n",
    "                          if torch.cuda.is_available() else \"CPU\"),\n",
    "        }\n",
    "    ) as run:\n",
    "        start_time = time.time()\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        print(f\"Using device: {device}\")\n",
    "        # --- Models ---\n",
    "        netG = netG.to(device)\n",
    "        netD = netD.to(device)\n",
    "        print(\"Initializing weights...\")\n",
    "        netG.apply(weights_init)\n",
    "        netD.apply(weights_init)\n",
    "        print(\"Models initialized.\")\n",
    "        \n",
    "        # --- Loss Functions ---\n",
    "        criterionGAN = nn.BCEWithLogitsLoss() # Sigmoid is included\n",
    "        criterionL1 = nn.L1Loss()\n",
    "        # --- Optimizers ---\n",
    "        optimizerG = optim.Adam(netG.parameters(), lr=lr_g, betas=(beta1, 0.999))\n",
    "        optimizerD = optim.Adam(netD.parameters(), lr=lr_d, betas=(beta1, 0.999))\n",
    "        # --- Learning Rate Schedulers ---\n",
    "        def lambda_rule(epoch):\n",
    "            lr_l = 1.0 - max(0, epoch + 1 - (n_epochs - n_epochs_decay)) / float(n_epochs_decay + 1)\n",
    "            return lr_l\n",
    "        schedulerG = optim.lr_scheduler.LambdaLR(optimizerG, lr_lambda=lambda_rule)\n",
    "        schedulerD = optim.lr_scheduler.LambdaLR(optimizerD, lr_lambda=lambda_rule)\n",
    "        \n",
    "        # --- Training Loop ---\n",
    "        print(\"Starting Training Loop...\")\n",
    "        best_val_g_l1_loss = float('inf')\n",
    "        best_path_g = None\n",
    "        best_path_d = None\n",
    "        for epoch in trange(n_epochs, desc=\"Epochs\"):\n",
    "            epoch_start_time = time.time()\n",
    "            netG.train()\n",
    "            netD.train()\n",
    "\n",
    "            epoch_loss_g = 0\n",
    "            epoch_loss_d = 0\n",
    "            epoch_loss_g_gan = 0\n",
    "            epoch_loss_g_l1 = 0\n",
    "            for i, batch_data in enumerate(train_loader):\n",
    "                real_A = batch_data['t1'].to(device)\n",
    "                real_B = batch_data['t2'].to(device)\n",
    "                # ---------------------\n",
    "                #  Train Discriminator\n",
    "                # ---------------------\n",
    "                optimizerD.zero_grad()\n",
    "                # Real images\n",
    "                # Discriminator input: concatenate T1 (real_A) and real T2 (real_B)\n",
    "                real_AB = torch.cat((real_A, real_B), 1)\n",
    "                pred_real = netD(real_AB)\n",
    "                # Label smoothing: use 0.9 for real instead of 1.0\n",
    "                target_real = torch.full(pred_real.shape, 0.9 if torch.rand(1).item() > 0.05 else 1.0, device=device, dtype=torch.float32) # Small chance of flipping for robustness\n",
    "                loss_D_real = criterionGAN(pred_real, target_real)\n",
    "\n",
    "                # Fake images\n",
    "                fake_B = netG(real_A).detach() # Detach to avoid backprop to G here\n",
    "                # Discriminator input: concatenate T1 (real_A) and fake T2 (fake_B)\n",
    "                fake_AB = torch.cat((real_A, fake_B), 1)\n",
    "                pred_fake = netD(fake_AB)\n",
    "                # Label smoothing: use 0.1 for fake instead of 0.0\n",
    "                target_fake = torch.full(pred_fake.shape, 0.1 if torch.rand(1).item() > 0.05 else 0.0, device=device, dtype=torch.float32)\n",
    "                loss_D_fake = criterionGAN(pred_fake, target_fake)\n",
    "\n",
    "                # Total discriminator loss\n",
    "                loss_D = (loss_D_real + loss_D_fake) * 0.5\n",
    "                loss_D.backward()\n",
    "                optimizerD.step()\n",
    "\n",
    "                epoch_loss_d += loss_D.item()\n",
    "                \n",
    "                # -----------------\n",
    "                #  Train Generator\n",
    "                # -----------------\n",
    "                optimizerG.zero_grad()\n",
    "\n",
    "                # Generate fake T2\n",
    "                fake_B_for_G = netG(real_A)\n",
    "                # Discriminator input for G's adversarial loss\n",
    "                fake_AB_for_G = torch.cat((real_A, fake_B_for_G), 1)\n",
    "                pred_fake_G = netD(fake_AB_for_G)\n",
    "                # Generator wants discriminator to think fake images are real\n",
    "                target_real_for_G = torch.ones_like(pred_fake_G, device=device, dtype=torch.float32) # No smoothing for G's target\n",
    "                loss_G_GAN = criterionGAN(pred_fake_G, target_real_for_G)\n",
    "\n",
    "                # L1 loss (reconstruction loss)\n",
    "                loss_G_L1 = criterionL1(fake_B_for_G, real_B) * lambda_l1\n",
    "\n",
    "                # Total generator loss\n",
    "                loss_G = loss_G_GAN + loss_G_L1\n",
    "                loss_G.backward()\n",
    "                optimizerG.step()\n",
    "\n",
    "                epoch_loss_g += loss_G.item()\n",
    "                epoch_loss_g_gan += loss_G_GAN.item()\n",
    "                epoch_loss_g_l1 += loss_G_L1.item()\n",
    "\n",
    "            # Update learning rates\n",
    "            schedulerG.step()\n",
    "            schedulerD.step()\n",
    "            \n",
    "            # --- Training Losses ---\n",
    "            avg_loss_d = epoch_loss_d / len(train_loader)\n",
    "            avg_loss_g = epoch_loss_g / len(train_loader)\n",
    "            avg_loss_g_gan = epoch_loss_g_gan / len(train_loader)\n",
    "            avg_loss_g_l1 = epoch_loss_g_l1 / len(train_loader)\n",
    "            \n",
    "            # -----------------------\n",
    "            #  Validation Phase\n",
    "            # -----------------------\n",
    "            netG.eval()\n",
    "            netD.eval()\n",
    "            val_loss_g = 0\n",
    "            val_loss_d = 0\n",
    "            val_loss_g_gan = 0\n",
    "            val_loss_g_l1 = 0\n",
    "\n",
    "            with torch.no_grad():\n",
    "                for val_batch in val_loader:\n",
    "                    real_A = val_batch['t1'].to(device)\n",
    "                    real_B = val_batch['t2'].to(device)\n",
    "\n",
    "                    # --- Discriminator ---\n",
    "                    real_AB = torch.cat((real_A, real_B), 1)\n",
    "                    pred_real = netD(real_AB)\n",
    "                    target_real = torch.ones_like(pred_real, device=device)\n",
    "                    loss_D_real = criterionGAN(pred_real, target_real)\n",
    "\n",
    "                    fake_B = netG(real_A)\n",
    "                    fake_AB = torch.cat((real_A, fake_B), 1)\n",
    "                    pred_fake = netD(fake_AB)\n",
    "                    target_fake = torch.zeros_like(pred_fake, device=device)\n",
    "                    loss_D_fake = criterionGAN(pred_fake, target_fake)\n",
    "\n",
    "                    loss_D = (loss_D_real + loss_D_fake) * 0.5\n",
    "                    val_loss_d += loss_D.item()\n",
    "\n",
    "                    # --- Generator ---\n",
    "                    pred_fake_G = netD(fake_AB)\n",
    "                    target_real_for_G = torch.ones_like(pred_fake_G, device=device)\n",
    "                    loss_G_GAN = criterionGAN(pred_fake_G, target_real_for_G)\n",
    "                    loss_G_L1 = criterionL1(fake_B, real_B) * lambda_l1\n",
    "                    loss_G = loss_G_GAN + loss_G_L1\n",
    "\n",
    "                    val_loss_g += loss_G.item()\n",
    "                    val_loss_g_gan += loss_G_GAN.item()\n",
    "                    val_loss_g_l1 += loss_G_L1.item()\n",
    "\n",
    "            # --- Average Validation Losses ---\n",
    "            avg_val_loss_d = val_loss_d / len(val_loader)\n",
    "            avg_val_loss_g = val_loss_g / len(val_loader)\n",
    "            avg_val_loss_g_gan = val_loss_g_gan / len(val_loader)\n",
    "            avg_val_loss_g_l1 = val_loss_g_l1 / len(val_loader)\n",
    "\n",
    "            epoch_duration = time.time() - epoch_start_time\n",
    "                    \n",
    "            wandb.log(\n",
    "                {\n",
    "                    \"epoch\": epoch + 1,\n",
    "                    \"loss_G\": avg_loss_g,\n",
    "                    \"loss_G_GAN\": avg_loss_g_gan,\n",
    "                    \"loss_G_L1\": avg_loss_g_l1,\n",
    "                    \"loss_D\": avg_loss_d,\n",
    "                    \"val_loss_G\": avg_val_loss_g,\n",
    "                    \"val_loss_G_GAN\": avg_val_loss_g_gan,\n",
    "                    \"val_loss_G_L1\": avg_val_loss_g_l1,\n",
    "                    \"val_loss_D\": avg_val_loss_d,\n",
    "                    \"lr_G\": optimizerG.param_groups[0]['lr'],\n",
    "                    \"lr_D\": optimizerD.param_groups[0]['lr'],\n",
    "                    \"epoch_time_minutes\": epoch_duration // 60\n",
    "                }\n",
    "            )\n",
    "            if epoch % 5 == 0 or (epoch + 1) == n_epochs or val_loss_g_l1 < best_val_g_l1_loss:\n",
    "                # Log sample images\n",
    "                with torch.no_grad():\n",
    "                    sample_batch = next(iter(val_loader))\n",
    "                    sample_real_A = sample_batch['t1'][0].unsqueeze(0).to(device)\n",
    "                    sample_real_B = sample_batch['t2'][0].to(device)\n",
    "                    sample_fake_B = netG(sample_real_A)\n",
    "                    imgs = torch.stack([sample_real_A.squeeze(0),\n",
    "                                        sample_real_B,\n",
    "                                        preprocess_image(sample_fake_B.squeeze(0))], dim=0)\n",
    "                    grid = torchvision.utils.make_grid(imgs, nrow=3, scale_each=True)\n",
    "                    wandb.log({'each5e_generation': wandb.Image(grid, caption=f'Epoch {epoch + 1}')})\n",
    "                \n",
    "                if val_loss_g_l1 < best_val_g_l1_loss:\n",
    "                    # Save best models\n",
    "                    best_val_g_l1_loss = val_loss_g_l1\n",
    "                    path_g = f'{CHECKPOINTS_PATH}/checkpoint_{exp_name}_{epoch+1}__generator_best.pth'\n",
    "                    path_d = f'{CHECKPOINTS_PATH}/checkpoint_{exp_name}_{epoch+1}__discriminator_best_g.pth' # Note: discriminato is the one that was trained with the best generator\n",
    "                    torch.save({\n",
    "                        'epoch': epoch+1,\n",
    "                        'model_state_dict': netG.state_dict(),\n",
    "                        'optimizer_state_dict': optimizerG.state_dict(),\n",
    "                    }, path_g)\n",
    "                    torch.save({\n",
    "                        'epoch': epoch+1,\n",
    "                        'model_state_dict': netD.state_dict(),\n",
    "                        'optimizer_state_dict': optimizerD.state_dict(),\n",
    "                    }, path_d)\n",
    "                    if best_path_g is not None and os.path.exists(best_path_g):\n",
    "                        os.remove(best_path_g)\n",
    "                    if best_path_d is not None and os.path.exists(best_path_d):\n",
    "                        os.remove(best_path_d)\n",
    "                    best_path_g = path_g\n",
    "                    best_path_d = path_d\n",
    "                else:    \n",
    "                    # Save backups every 5 epochs\n",
    "                    torch.save({\n",
    "                            'epoch': epoch+1,\n",
    "                            'model_state_dict': netG.state_dict(),\n",
    "                            'optimizer_state_dict': optimizerG.state_dict(),\n",
    "                        }, f'{CHECKPOINTS_PATH}/backups/checkpoint_{exp_name}_{epoch+1}__generator.pth')\n",
    "                    torch.save({\n",
    "                            'epoch': epoch+1,\n",
    "                            'model_state_dict': netD.state_dict(),\n",
    "                            'optimizer_state_dict': optimizerD.state_dict(),\n",
    "                        }, f'{CHECKPOINTS_PATH}/backups/checkpoint_{exp_name}_{epoch+1}__discriminator.pth')\n",
    "        wandb.log({\"total_running_hours\": (time.time() - start_time) // 3600})\n",
    "        return best_path_g, best_path_d\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e65626a",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def generate_and_save_predictions(gan_model: UNetGenerator2D, test_loader: DataLoader, device: str, output_dir: str = OUTPUT_DIR, just_one_batch: bool = False):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    gan_model.eval()\n",
    "\n",
    "    all_outputs = []\n",
    "\n",
    "    for idx, batch in enumerate(tqdm(test_loader, desc=\"Generating Predictions\")):\n",
    "        with torch.no_grad():\n",
    "            real_A = batch[\"t1\"].to(device)  # [B, 1, H, W]\n",
    "            real_B = batch[\"t2\"].to(device)  # [B, 1, H, W]\n",
    "            filenames = batch[\"filename\"]  # list of strings (length B)\n",
    "            # Generate fake T2 images\n",
    "            gen_images = gan_model(real_A)  # [B, 1, H, W]\n",
    "\n",
    "            \n",
    "        for i in range(real_A.size(0)):\n",
    "            sample = {\n",
    "                \"filename\": filenames[i],\n",
    "                \"input\": real_A[i].cpu(),         # torch.Tensor [1, H, W]\n",
    "                \"target\": real_B[i].cpu(),\n",
    "                \"prediction\": gen_images[i].cpu()\n",
    "            }\n",
    "\n",
    "            torch.save(sample, os.path.join(output_dir, f\"{filenames[i]}.pt\"))\n",
    "            all_outputs.append(sample)\n",
    "            \n",
    "        if just_one_batch:\n",
    "            break\n",
    "        wandb.log({\"prediction_progress\": idx})\n",
    "\n",
    "    return all_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb74f336",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PredictionDataset(Dataset):\n",
    "    def __init__(self, directory):\n",
    "        super().__init__()\n",
    "        self.directory = directory\n",
    "        self.files = sorted([\n",
    "            f for f in os.listdir(directory) if f.endswith('.pt')\n",
    "        ])\n",
    "        if not self.files:\n",
    "            raise ValueError(f\"No .pt files found in directory: {directory}\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if isinstance(idx, slice):\n",
    "            return [self[i] for i in range(*idx.indices(len(self)))]\n",
    "        file_path = os.path.join(self.directory, self.files[idx])\n",
    "        data = torch.load(file_path)\n",
    "        pred = data[\"prediction\"]       # expected shape: [1, H, W] or [C, H, W]\n",
    "        gt = data[\"target\"]\n",
    "        return pred, gt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6628197f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_ssim_from_dataset(dataset):\n",
    "    ssim_scores = []\n",
    "    mse_scores = []\n",
    "\n",
    "    example_pred = None\n",
    "    example_gt = None\n",
    "\n",
    "    for i in range(len(dataset)):\n",
    "        pred, gt = dataset[i]  # tensors [1, H, W]\n",
    "\n",
    "        # Convert to numpy and squeeze channel\n",
    "        pred_np = pred.squeeze().cpu().numpy()\n",
    "        gt_np = gt.squeeze().cpu().numpy()\n",
    "\n",
    "        pred_np = normalize(percnorm(pred_np))\n",
    "        gt_np = normalize(percnorm(gt_np))\n",
    "\n",
    "        # Compute SSIM\n",
    "        ssim_val = ssim_fn(pred_np, gt_np, data_range=1.0)\n",
    "        ssim_scores.append(ssim_val)\n",
    "\n",
    "        # Compute MSE\n",
    "        mse_val = F.mse_loss(pred, gt).item()\n",
    "        mse_scores.append(mse_val)\n",
    "\n",
    "        # Store one example for visualization\n",
    "        if i == 4 and example_pred is None:\n",
    "            example_pred = pred_np\n",
    "            example_gt = gt_np\n",
    "\n",
    "    ssim_scores = np.array(ssim_scores)\n",
    "    mse_scores = np.array(mse_scores)\n",
    "    \n",
    "    summary = pd.DataFrame({\n",
    "        \"Metric\": [\"SSIM\", \"MSE\"],\n",
    "        \"Mean\": [ssim_scores.mean(), mse_scores.mean()],\n",
    "        \"Variance\": [ssim_scores.var(), mse_scores.var()]\n",
    "    })\n",
    "\n",
    "    # Visualize example\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(8, 4))\n",
    "    axs[0].imshow(example_gt, cmap='gray')\n",
    "    axs[0].set_title(\"Ground Truth\")\n",
    "    axs[0].axis(\"off\")\n",
    "\n",
    "    axs[1].imshow(example_pred, cmap='gray')\n",
    "    axs[1].set_title(\"Prediction\")\n",
    "    axs[1].axis(\"off\")\n",
    "\n",
    "    plt.suptitle(\"Example Comparison\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f8392e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "def get_norm_layer():\n",
    "    norm_layer = functools.partial(nn.InstanceNorm3d, affine=False, track_running_stats=False)\n",
    "    return norm_layer\n",
    "\n",
    "norm_layer_g = get_norm_layer()\n",
    "norm_layer_d = get_norm_layer()\n",
    "\n",
    "netG = UNetGenerator2D(\n",
    "    in_channels=1, \n",
    "    out_channels=1, \n",
    "    num_downs=5, \n",
    "    ngf=64, \n",
    "    norm_layer=norm_layer_g, \n",
    "    use_dropout=False\n",
    ")\n",
    "\n",
    "netD = NLayerDiscriminator2D(\n",
    "    input_nc=2,\n",
    "    ndf=64,\n",
    "    n_layers=3,\n",
    "    norm_layer=norm_layer_d\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f75762",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "exp_name = \"pix2pix-t1t2-brain300e\"\n",
    "best_path_g, best_path_d = train_GAN(\n",
    "    netG=netG,\n",
    "    netD=netD,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    project=\"FlowMatching-Baselines\",\n",
    "    exp_name=exp_name,\n",
    "    notes=\"Baseline Pix2Pix for T1-T2 conversion\",\n",
    "    n_epochs=300,\n",
    "    n_epochs_decay=100,\n",
    "    lr_g=0.0002,\n",
    "    lr_d=0.00005,\n",
    "    beta1=0.5,\n",
    "    lambda_l1=100.0\n",
    ")\n",
    "checkpoint = torch.load(best_path_g, map_location=device)\n",
    "netG.load_state_dict(checkpoint['model_state_dict'])\n",
    "netG.to(device)\n",
    "\n",
    "with wandb.init(\n",
    "    project = 'FlowMatching-Baselines',\n",
    "    name=f'evaluation-{exp_name}',\n",
    "    notes=\"Evaluation of the diffusion model on the test set.\",\n",
    "):\n",
    "    generate_and_save_predictions(\n",
    "        cn_model=netG,\n",
    "        test_loader=test_loader,\n",
    "        device=device,\n",
    "        output_dir=f'{OUTPUT_DIR}/{exp_name}',\n",
    "        just_one_batch=False)\n",
    "    out_dataset = PredictionDataset(f'{OUTPUT_DIR}/{exp_name}')\n",
    "\n",
    "    summary = compute_ssim_from_dataset(out_dataset)\n",
    "    wandb.log({\"eval/metrics\": wandb.Table(dataframe=summary)})\n",
    "    wandb.log({\"eval/ssim_mean\": summary[\"Mean\"][0]})\n",
    "    wandb.log({\"eval/mse_mean\": summary[\"Mean\"][1]})\n",
    "    wandb.log({\"eval/ssim_var\": summary[\"Variance\"][0]})\n",
    "    wandb.log({\"eval/mse_var\": summary[\"Variance\"][1]})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "medical (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
