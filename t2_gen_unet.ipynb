{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8fee7f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "DATAPATH = DATAPATH = '/home/andrea_moschetto/flow_matching_t1t2/data'\n",
    "print(DATAPATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e2823cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "\n",
    "class UnifiedBrainDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None, is_train=True, split_ratio=0.8, seed=42):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.is_train = is_train\n",
    "        self.split_ratio = split_ratio\n",
    "        self.seed = seed\n",
    "        self.samples = self._create_file_pairs()\n",
    "        self._split_dataset()\n",
    "        \n",
    "    def _create_file_pairs(self):\n",
    "        t1_dir = os.path.join(self.root_dir, \"t1\")\n",
    "        t2_dir = os.path.join(self.root_dir, \"t2\")\n",
    "        \n",
    "        t1_files = set(os.listdir(t1_dir))\n",
    "        t2_files = set(os.listdir(t2_dir))\n",
    "        common_files = list(t1_files.intersection(t2_files))\n",
    "        common_files.sort()  # garantisce ordine ripetibile\n",
    "\n",
    "        pairs = [(os.path.join(t1_dir, fname), os.path.join(t2_dir, fname)) for fname in common_files]\n",
    "        return pairs\n",
    "\n",
    "    def _split_dataset(self):\n",
    "        random.seed(self.seed)\n",
    "        random.shuffle(self.samples)\n",
    "        \n",
    "        split_idx = int(len(self.samples) * self.split_ratio)\n",
    "        if self.is_train:\n",
    "            self.samples = self.samples[:split_idx]\n",
    "        else:\n",
    "            self.samples = self.samples[split_idx:]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        t1_path, t2_path = self.samples[idx]\n",
    "        t1_image = Image.open(t1_path).convert(\"L\")\n",
    "        t2_image = Image.open(t2_path).convert(\"L\")\n",
    "        \n",
    "        if self.transform:\n",
    "            t1_image = self.transform(t1_image)\n",
    "            t2_image = self.transform(t2_image)\n",
    "\n",
    "        return {\n",
    "            \"t1\": t1_image,\n",
    "            \"t2\": t2_image,\n",
    "            \"filename\": os.path.basename(t1_path)\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ab03501f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch import Tensor\n",
    "from generative.networks.nets import DiffusionModelUNet\n",
    "\n",
    "\n",
    "def euler_step(model: DiffusionModelUNet, x_t: Tensor, t_start: Tensor, t_end: Tensor):\n",
    "    # delta_t shape (B, 1, 1, 1)\n",
    "    delta_t = (t_end - t_start).view(-1, 1, 1, 1)\n",
    "    \n",
    "    # model si aspetta t come tensor (B,)\n",
    "    v_hat = model(x_t, t_start)\n",
    "    \n",
    "    x_next = x_t + delta_t * v_hat\n",
    "    \n",
    "    return x_next\n",
    "\n",
    "@torch.no_grad()\n",
    "def generate(model: nn.Module, x_T: Tensor, n_steps: int = 20):\n",
    "    model.eval()\n",
    "    \n",
    "    device = x_T.device\n",
    "    batch_size = x_T.shape[0]\n",
    "    \n",
    "    time_steps = torch.linspace(0.0, 1.0, n_steps + 1, device=device, dtype=torch.float32)\n",
    "    \n",
    "    x = x_T\n",
    "    for i in range(n_steps):\n",
    "        t_start = time_steps[i].expand(batch_size)\n",
    "        t_end = time_steps[i + 1].expand(batch_size)\n",
    "        x = euler_step(model, x_t=x, t_start=t_start, t_end=t_end)\n",
    "    \n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a8baa72b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a03b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torchvision\n",
    "import wandb\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "def log_generation(model, epoch, device, reference_image=None, use_wandb=True):\n",
    "    with torch.no_grad():\n",
    "        noise = torch.randn(1, 1, 224, 192).to(device)  #  1, 1, 224, 192\n",
    "        x_gen = generate(model=model, x_T=noise, n_steps=100)\n",
    "        if reference_image is not None:\n",
    "            # stack [real, generated]\n",
    "            images = torch.cat([reference_image, x_gen], dim=0)\n",
    "        else:\n",
    "            images = x_gen\n",
    "        \n",
    "        grid = torchvision.utils.make_grid(images, nrow=2, normalize = True)\n",
    "        if use_wandb:\n",
    "            wandb.log(\n",
    "                {\"generation\": [wandb.Image(grid, caption=f\"Epoch {epoch}\")]})\n",
    "        return grid\n",
    "\n",
    "\n",
    "def show_grid(grid):\n",
    "    # grid è un tensore [C, H, W], lo trasformiamo in un'immagine visualizzabile\n",
    "    np_grid = grid.permute(1, 2, 0).cpu().numpy()  # da [C,H,W] a [H,W,C]\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.imshow(np_grid)\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "debe8a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import trange, tqdm\n",
    "import wandb\n",
    "import os\n",
    "\n",
    "CHECKPOINTS_PATH = '/home/andrea_moschetto/flow_matching_t1t2/checkpoints'\n",
    "if not os.path.exists(CHECKPOINTS_PATH):\n",
    "    os.makedirs(CHECKPOINTS_PATH)\n",
    "\n",
    "\n",
    "def train_flow(model: DiffusionModelUNet, train_loader: DataLoader, val_loader: DataLoader, project: str, exp_name: str, notes: str, n_epochs: int = 10, lr : float = 1e-3):\n",
    "    with wandb.init(\n",
    "        project=project,\n",
    "        name=exp_name,\n",
    "        notes=notes,\n",
    "        tags=[\"flow\", \"brain\", \"diffusion\"],\n",
    "        config={\n",
    "            'model': model.__class__.__name__,\n",
    "            'epochs': n_epochs,\n",
    "            'batch_size': train_loader.batch_size,\n",
    "            'num_workers': train_loader.num_workers,\n",
    "            'optimizer': 'Adam',\n",
    "            'learning_rate': lr,\n",
    "            'loss_function': 'MSELoss',\n",
    "            'device': str(torch.cuda.get_device_name(0)\n",
    "                          if torch.cuda.is_available() else \"CPU\"),\n",
    "        }\n",
    "    ) as run:\n",
    "\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        print(\"Using\", torch.cuda.get_device_name(0)\n",
    "                if torch.cuda.is_available() else \"CPU\")\n",
    "\n",
    "        model.to(device)\n",
    "        model.train()\n",
    "\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "        criterion = nn.MSELoss()\n",
    "        old_epoch = 0\n",
    "        \n",
    "        start_time = time.time()\n",
    "        for e in trange(n_epochs, desc=\"Epochs\"):\n",
    "            start_e_time = time.time()\n",
    "            # Training\n",
    "            model.train()\n",
    "            train_losses = []\n",
    "            for batch in tqdm(train_loader, desc=f\"Training epoch {e}\"):\n",
    "                x_1 = batch[\"t2\"].to(device)  # [B, 1, H, W]\n",
    "                x_0 = torch.randn_like(x_1).to(device)  # [B, 1, H, W]\n",
    "\n",
    "                B = x_0.shape[0]\n",
    "                t = torch.rand(B, device=device)  # B \n",
    "                \n",
    "                t_img = t.view(B, 1, 1, 1)  # [B, 1, 1, 1] for broadcasting\n",
    "\n",
    "                x_t = (1 - t_img) * x_0 + t_img * x_1         # [B, 1, H, W]\n",
    "                dx_t = x_1 - x_0                              # [B, 1, H, W]\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                pred = model(x_t, t)  # [B, 1, H, W]\n",
    "                loss = criterion(pred, dx_t)\n",
    "                train_losses.append(loss.item())\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "            wandb.log({\"train_loss\": sum(train_losses) / len(train_losses)})\n",
    "            \n",
    "            # Validation\n",
    "            model.eval()\n",
    "            val_losses = []\n",
    "            with torch.no_grad():\n",
    "                for batch in val_loader:\n",
    "                    x_1 = batch[\"t2\"].to(device)\n",
    "                    x_0 = torch.randn_like(x_1, device=device)\n",
    "                    B = x_0.shape[0]\n",
    "                    t = torch.rand(B, device=device)\n",
    "                    t_img = t.view(B, 1, 1, 1)\n",
    "                    x_t = (1 - t_img) * x_0 + t_img * x_1\n",
    "                    dx_t = x_1 - x_0\n",
    "\n",
    "                    pred = model(x_t, t)\n",
    "                    val_loss = criterion(pred, dx_t)\n",
    "                    val_losses.append(val_loss.item())\n",
    "            wandb.log({\"val_loss\": sum(val_losses) / len(val_losses)})\n",
    "            e_time = time.time() - start_e_time\n",
    "            wandb.log({\"epoch_time_minutes\": e_time // 60})\n",
    "\n",
    "\n",
    "            # Checkpoint\n",
    "            if e % 5 == 0 or e == n_epochs - 1:\n",
    "                sample_batch = next(iter(train_loader))  # just one batch\n",
    "                reference = sample_batch[\"t2\"][0].unsqueeze(0).to(device)  # [1, 1, H, W]\n",
    "                log_generation(model, epoch=e, device=device, reference_image=reference)\n",
    "\n",
    "                torch.save({\n",
    "                    'epoch': e,\n",
    "                    'model_state_dict': model.state_dict(),\n",
    "                    'optimizer_state_dict': optimizer.state_dict(),\n",
    "                }, f'{CHECKPOINTS_PATH}/checkpoint_{exp_name}_{e}.pth')\n",
    "                if os.path.exists(f'{CHECKPOINTS_PATH}/checkpoint_{exp_name}_{old_epoch}.pth'):\n",
    "                    os.remove(\n",
    "                        f'{CHECKPOINTS_PATH}/checkpoint_{exp_name}_{old_epoch}.pth')\n",
    "                old_epoch = e\n",
    "        end_time = time.time()\n",
    "        elapsed_time = end_time - start_time\n",
    "        wandb.log({\"total_running_hours\": elapsed_time // 3600})\n",
    "        print(f\"Training completed in {elapsed_time // 60:.0f}m {elapsed_time % 60:.0f}s\")\n",
    "    print(\"Training complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ad318d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Pad(padding=(5, 3, 5, 3), fill=0),\n",
    "    transforms.ToTensor(),  # Normalize to [0, 1]\n",
    "])\n",
    "\n",
    "train_dataset = UnifiedBrainDataset(root_dir=DATAPATH, transform=transform, is_train=True)\n",
    "train_loader = DataLoader(train_dataset, batch_size=4, num_workers=2, shuffle=True)\n",
    "val_dataset = UnifiedBrainDataset(root_dir=DATAPATH, transform=transform, is_train=False)\n",
    "val_loader = DataLoader(val_dataset, batch_size=4, num_workers=2, shuffle=False)\n",
    "\n",
    "model = DiffusionModelUNet(\n",
    "    spatial_dims=2,  #  2D\n",
    "    in_channels=1,  #  x \n",
    "    out_channels=1  #  predice delta_x_t\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d2e582",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_flow(\n",
    "    model=model, \n",
    "    train_loader=train_loader, \n",
    "    val_loader=val_loader,\n",
    "    project='flowmatching-t2gen', \n",
    "    exp_name=\"unetflow-t2gen-50e\",\n",
    "    notes=\"UNet flow model for T2 generation\",\n",
    "    n_epochs=50, \n",
    "    lr=1e-4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "medical (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
