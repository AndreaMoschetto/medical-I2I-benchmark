{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "917feaf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import torch\n",
    "import time\n",
    "from torch import nn\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "from torch import Tensor\n",
    "from PIL import Image\n",
    "\n",
    "from generative.networks.nets import DiffusionModelUNet\n",
    "import wandb\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import trange, tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from skimage.metrics import structural_similarity as ssim_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fee7f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATAPATH = DATAPATH = '/home/andrea_moschetto/flow_matching_t1t2/data'\n",
    "OUTPUT_DIR = \"/home/andrea_moschetto/flow_matching_t1t2/outputs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e2823cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UnifiedBrainDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None, split=\"train\", seed=42):\n",
    "        assert split in [\"train\", \"val\", \"test\"], \"split must be 'train', 'val' or 'test'\"\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.split = split\n",
    "        self.seed = seed\n",
    "        self.samples = self._create_file_pairs()\n",
    "        self._split_dataset()\n",
    "\n",
    "    def _create_file_pairs(self):\n",
    "        t1_dir = os.path.join(self.root_dir, \"t1\")\n",
    "        t2_dir = os.path.join(self.root_dir, \"t2\")\n",
    "\n",
    "        t1_files = set(os.listdir(t1_dir))\n",
    "        t2_files = set(os.listdir(t2_dir))\n",
    "        common_files = list(t1_files.intersection(t2_files))\n",
    "        common_files.sort()\n",
    "\n",
    "        pairs = [(os.path.join(t1_dir, fname), os.path.join(t2_dir, fname)) for fname in common_files]\n",
    "        return pairs\n",
    "\n",
    "    def _split_dataset(self):\n",
    "        random.seed(self.seed)\n",
    "        random.shuffle(self.samples)\n",
    "\n",
    "        n_total = len(self.samples)\n",
    "        n_train = int(n_total * 0.80)\n",
    "        n_val = int(n_total * 0.05)\n",
    "        n_test = n_total - n_train - n_val\n",
    "\n",
    "        if self.split == \"train\":\n",
    "            self.samples = self.samples[:n_train]\n",
    "        elif self.split == \"val\":\n",
    "            self.samples = self.samples[n_train:n_train + n_val]\n",
    "        elif self.split == \"test\":\n",
    "            self.samples = self.samples[n_train + n_val:]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        t1_path, t2_path = self.samples[idx]\n",
    "        t1_image = Image.open(t1_path).convert(\"L\")\n",
    "        t2_image = Image.open(t2_path).convert(\"L\")\n",
    "\n",
    "        if self.transform:\n",
    "            t1_image = self.transform(t1_image)\n",
    "            t2_image = self.transform(t2_image)\n",
    "\n",
    "        return {\n",
    "            \"t1\": t1_image,\n",
    "            \"t2\": t2_image,\n",
    "            \"filename\": os.path.basename(t1_path)\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ab03501f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def euler_step(model: DiffusionModelUNet, x_t: Tensor, t_start: Tensor, t_end: Tensor):\n",
    "    # delta_t shape (B, 1, 1, 1)\n",
    "    delta_t = (t_end - t_start).view(-1, 1, 1, 1)\n",
    "    \n",
    "    # model si aspetta t come tensor (B,)\n",
    "    v_hat = model(x_t, t_start)\n",
    "    \n",
    "    x_next = x_t + delta_t * v_hat\n",
    "    \n",
    "    return x_next\n",
    "\n",
    "@torch.no_grad()\n",
    "def generate(model: nn.Module, x_T: Tensor, n_steps: int = 20):\n",
    "    model.eval()\n",
    "    \n",
    "    device = x_T.device\n",
    "    batch_size = x_T.shape[0]\n",
    "    \n",
    "    time_steps = torch.linspace(0.0, 1.0, n_steps + 1, device=device, dtype=torch.float32)\n",
    "    \n",
    "    x = x_T\n",
    "    for i in range(n_steps):\n",
    "        t_start = time_steps[i].expand(batch_size)\n",
    "        t_end = time_steps[i + 1].expand(batch_size)\n",
    "        x = euler_step(model, x_t=x, t_start=t_start, t_end=t_end)\n",
    "    \n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "46a03b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_generation(model, epoch, device, n_steps: int, reference_image=None, use_wandb=True):\n",
    "    with torch.no_grad():\n",
    "        if reference_image is not None:\n",
    "            reference_t1, reference_t2 = reference_image  # t1 = input, t2 = ground truth\n",
    "            # input al modello = t1\n",
    "            x_T = reference_t1.to(device)\n",
    "            x_gen = generate(model=model, x_T=x_T, n_steps=n_steps)\n",
    "\n",
    "            # Visualizza t1 (input), t2 (vero), x_gen (generato)\n",
    "            images = torch.cat([reference_t1, reference_t2,\n",
    "                               x_gen], dim=0)  # [3, 1, H, W]\n",
    "        else:\n",
    "            raise ValueError(\n",
    "                \"reference_image must be provided when generating from t1.\")\n",
    "\n",
    "        grid = torchvision.utils.make_grid(images, nrow=3, normalize=True)\n",
    "\n",
    "        if use_wandb:\n",
    "            wandb.log({\n",
    "                \"generation\": [wandb.Image(grid, caption=f\"Epoch {epoch+1}\")]\n",
    "            })\n",
    "\n",
    "        return grid, x_gen\n",
    "\n",
    "\n",
    "def show_grid(grid):\n",
    "    # grid è un tensore [C, H, W], lo trasformiamo in un'immagine visualizzabile\n",
    "    np_grid = grid.permute(1, 2, 0).cpu().numpy()  # da [C,H,W] a [H,W,C]\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.imshow(np_grid)\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "debe8a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "CHECKPOINTS_PATH = '/home/andrea_moschetto/flow_matching_t1t2/checkpoints'\n",
    "if not os.path.exists(CHECKPOINTS_PATH):\n",
    "    os.makedirs(CHECKPOINTS_PATH)\n",
    "\n",
    "\n",
    "def train_flow(model: DiffusionModelUNet, train_loader: DataLoader, val_loader: DataLoader, project: str, exp_name: str, notes: str, n_epochs: int = 10, lr : float = 1e-3, generation_steps: int = 100):\n",
    "    with wandb.init(\n",
    "        project=project,\n",
    "        name=exp_name,\n",
    "        notes=notes,\n",
    "        tags=[\"flow\", \"brain\", \"diffusion\"],\n",
    "        config={\n",
    "            'model': model.__class__.__name__,\n",
    "            'epochs': n_epochs,\n",
    "            'batch_size': train_loader.batch_size,\n",
    "            'num_workers': train_loader.num_workers,\n",
    "            'optimizer': 'Adam',\n",
    "            'learning_rate': lr,\n",
    "            'loss_function': 'MSELoss',\n",
    "            'generation_steps': generation_steps,\n",
    "            'device': str(torch.cuda.get_device_name(0)\n",
    "                          if torch.cuda.is_available() else \"CPU\"),\n",
    "        }\n",
    "    ) as run:\n",
    "\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        print(\"Using\", torch.cuda.get_device_name(0)\n",
    "                if torch.cuda.is_available() else \"CPU\")\n",
    "\n",
    "        model.to(device)\n",
    "        model.train()\n",
    "\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "        criterion = nn.MSELoss()\n",
    "\n",
    "        best_val_loss = float(\"inf\")\n",
    "        best_model_path = None\n",
    "        start_time = time.time()\n",
    "        for e in trange(n_epochs, desc=\"Epochs\"):\n",
    "            start_e_time = time.time()\n",
    "            # Training\n",
    "            model.train()\n",
    "            train_losses = []\n",
    "            for batch in tqdm(train_loader, desc=f\"Training epoch {e}\"):\n",
    "                x_1 = batch[\"t2\"].to(device)  # [B, 1, H, W]\n",
    "                x_0 = batch[\"t1\"].to(device)  # [B, 1, H, W]  # torch.randn_like(x_1).to(device)  # [B, 1, H, W]\n",
    "                # add the corresponding t1 to the second channel of x_0\n",
    "                \n",
    "                B = x_0.shape[0]\n",
    "                t = torch.rand(B, device=device)  # B \n",
    "                \n",
    "                t_img = t.view(B, 1, 1, 1)  # [B, 1, 1, 1] for broadcasting\n",
    "\n",
    "                x_t = (1 - t_img) * x_0 + t_img * x_1         # [B, 1, H, W]\n",
    "                dx_t = x_1 - x_0                              # [B, 1, H, W]\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                pred = model(x_t, t)  # [B, 1, H, W]\n",
    "                loss = criterion(pred, dx_t)\n",
    "                train_losses.append(loss.item())\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "            wandb.log({\"train_loss\": sum(train_losses) / len(train_losses)})\n",
    "            \n",
    "            # Validation\n",
    "            model.eval()\n",
    "            val_losses = []\n",
    "            with torch.no_grad():\n",
    "                for batch in val_loader:\n",
    "                    x_1 = batch[\"t2\"].to(device)\n",
    "                    x_0 = batch[\"t1\"].to(device)\n",
    "                    B = x_0.shape[0]\n",
    "                    t = torch.rand(B, device=device)\n",
    "                    t_img = t.view(B, 1, 1, 1)\n",
    "                    x_t = (1 - t_img) * x_0 + t_img * x_1\n",
    "                    dx_t = x_1 - x_0\n",
    "\n",
    "                    pred = model(x_t, t)\n",
    "                    val_loss = criterion(pred, dx_t)\n",
    "                    val_losses.append(val_loss.item())\n",
    "            batch_val_loss = sum(val_losses) / len(val_losses)\n",
    "            wandb.log({\"val_loss\": batch_val_loss})\n",
    "            e_time = time.time() - start_e_time\n",
    "            wandb.log({\"epoch_time_minutes\": e_time // 60})\n",
    "\n",
    "\n",
    "            # Checkpoint\n",
    "            if batch_val_loss < best_val_loss:\n",
    "                sample_batch = next(iter(val_loader))  # just one batch\n",
    "                reference_t2 = sample_batch[\"t2\"][0].unsqueeze(0).to(device)  # [1, 1, H, W]\n",
    "                reference_t1 = sample_batch[\"t1\"][0].unsqueeze(0).to(device)\n",
    "                reference = (reference_t1, reference_t2)\n",
    "                log_generation(model, epoch=e, device=device, n_steps=generation_steps, reference_image=reference)\n",
    "                \n",
    "                path = f'{CHECKPOINTS_PATH}/checkpoint_{exp_name}_{e+1}.pth'\n",
    "                torch.save({\n",
    "                    'epoch': e+1,\n",
    "                    'model_state_dict': model.state_dict(),\n",
    "                    'optimizer_state_dict': optimizer.state_dict(),\n",
    "                }, path)\n",
    "                if best_model_path is not None and os.path.exists(best_model_path):\n",
    "                    os.remove(best_model_path)\n",
    "                best_model_path = path\n",
    "                best_val_loss = batch_val_loss\n",
    "        end_time = time.time()\n",
    "        elapsed_time = end_time - start_time\n",
    "        wandb.log({\"total_running_hours\": elapsed_time // 3600})\n",
    "        print(f\"Training completed in {elapsed_time // 60:.0f}m {elapsed_time % 60:.0f}s\")\n",
    "    print(\"Training complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "cd8b29a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def generate_and_save_predictions(model, test_loader, device, output_dir=OUTPUT_DIR):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    model.eval()\n",
    "    \n",
    "    all_outputs = []\n",
    "\n",
    "    for batch in tqdm(test_loader, desc=\"Generating Predictions\"):\n",
    "        t1 = batch[\"t1\"].to(device)           # [B, 1, H, W]\n",
    "        t2 = batch[\"t2\"].to(device)           # [B, 1, H, W]\n",
    "        filenames = batch[\"filename\"]         # list of strings (length B)\n",
    "\n",
    "        x_gen = generate(model, x_T=t1, n_steps=300)\n",
    "        # print(t2.shape, x_gen.shape)\n",
    "\n",
    "        for i in range(t1.size(0)):\n",
    "            sample = {\n",
    "                \"filename\": filenames[i],\n",
    "                \"input\": t1[i].cpu(),         # torch.Tensor [1, H, W]\n",
    "                \"target\": t2[i].cpu(),\n",
    "                \"prediction\": x_gen[i].cpu()\n",
    "            }\n",
    "\n",
    "            torch.save(sample, os.path.join(output_dir, f\"{filenames[i]}.pt\"))\n",
    "            all_outputs.append(sample)\n",
    "\n",
    "    return all_outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "85105d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PredictionDataset(Dataset):\n",
    "    def __init__(self, directory):\n",
    "        super().__init__()\n",
    "        self.directory = directory\n",
    "        self.files = sorted([\n",
    "            f for f in os.listdir(directory) if f.endswith('.pt')\n",
    "        ])\n",
    "        if not self.files:\n",
    "            raise ValueError(f\"No .pt files found in directory: {directory}\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file_path = os.path.join(self.directory, self.files[idx])\n",
    "        data = torch.load(file_path)\n",
    "        pred = data[\"prediction\"]       # expected shape: [1, H, W] or [C, H, W]\n",
    "        gt = data[\"target\"]\n",
    "        return pred, gt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "4a495785",
   "metadata": {},
   "outputs": [],
   "source": [
    "def percnorm(arr, lperc=5, uperc=99.5):\n",
    "    \"\"\"\n",
    "    Remove outlier intensities from a brain component,\n",
    "    similar to Tukey's fences method.\n",
    "    \"\"\"\n",
    "    upperbound = np.percentile(arr, uperc)\n",
    "    lowerbound = np.percentile(arr, lperc)\n",
    "    arr[arr > upperbound] = upperbound\n",
    "    arr[arr < lowerbound] = lowerbound\n",
    "    return arr\n",
    "\n",
    "def normalize(img):\n",
    "    # img: [C, H, W]\n",
    "    img = (img - img.min())/ (img.max() - img.min() + 1e-8)\n",
    "    return img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "efeb967a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_ssim_from_dataset(dataset):\n",
    "    ssim_scores = []\n",
    "    mse_scores = []\n",
    "\n",
    "    example_pred = None\n",
    "    example_gt = None\n",
    "\n",
    "    crop = transforms.CenterCrop((182, 150))\n",
    "\n",
    "    for i in range(len(dataset)):\n",
    "        pred, gt = dataset[i]  # tensors [1, H, W]\n",
    "\n",
    "        # Convert to numpy and squeeze channel\n",
    "        pred_np = pred.squeeze().cpu().numpy()\n",
    "        gt_np = gt.squeeze().cpu().numpy()\n",
    "\n",
    "        pred_np = normalize(percnorm(pred_np))\n",
    "        gt_np = normalize(percnorm(gt_np))\n",
    "\n",
    "        # Compute SSIM\n",
    "        ssim_val = ssim_fn(pred_np, gt_np, data_range=1.0)\n",
    "        ssim_scores.append(ssim_val)\n",
    "\n",
    "        # Compute MSE\n",
    "        mse_val = F.mse_loss(pred, gt).item()\n",
    "        mse_scores.append(mse_val)\n",
    "\n",
    "        # Store one example for visualization\n",
    "        if i == 4 and example_pred is None:\n",
    "            example_pred = pred_np\n",
    "            example_gt = gt_np\n",
    "\n",
    "    ssim_scores = np.array(ssim_scores)\n",
    "    mse_scores = np.array(mse_scores)\n",
    "    \n",
    "    summary = pd.DataFrame({\n",
    "        \"Metric\": [\"SSIM\", \"MSE\"],\n",
    "        \"Mean\": [ssim_scores.mean(), mse_scores.mean()],\n",
    "        \"Variance\": [ssim_scores.var(), mse_scores.var()]\n",
    "    })\n",
    "\n",
    "    # Visualize example\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(8, 4))\n",
    "    axs[0].imshow(example_gt, cmap='gray')\n",
    "    axs[0].set_title(\"Ground Truth\")\n",
    "    axs[0].axis(\"off\")\n",
    "\n",
    "    axs[1].imshow(example_pred, cmap='gray')\n",
    "    axs[1].set_title(\"Prediction\")\n",
    "    axs[1].axis(\"off\")\n",
    "\n",
    "    plt.suptitle(\"Example Comparison\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ad318d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Pad(padding=(5, 3, 5, 3), fill=0),\n",
    "    transforms.ToTensor(),  # Normalize to [0, 1]\n",
    "])\n",
    "\n",
    "train_dataset = UnifiedBrainDataset(root_dir=DATAPATH, transform=transform, split=\"train\")\n",
    "train_loader = DataLoader(train_dataset, batch_size=6, num_workers=2, shuffle=True)\n",
    "val_dataset = UnifiedBrainDataset(root_dir=DATAPATH, transform=transform, split=\"val\")\n",
    "val_loader = DataLoader(val_dataset, batch_size=6, num_workers=2, shuffle=False)\n",
    "test_dataset = UnifiedBrainDataset(root_dir=DATAPATH, transform=transform, split=\"test\")\n",
    "test_loader = DataLoader(test_dataset, batch_size=6, num_workers=2, shuffle=False)\n",
    "\n",
    "model = DiffusionModelUNet(\n",
    "    spatial_dims=2,  #  2D\n",
    "    in_channels=1,  #  x \n",
    "    out_channels=1  #  predice delta_x_t\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d2e582",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "exp_name = \"unetflow-t1t2-150e\"\n",
    "modelpath = train_flow(\n",
    "    model=model, \n",
    "    train_loader=train_loader, \n",
    "    val_loader=val_loader,\n",
    "    project='flowmatching-t1-to-t2', \n",
    "    exp_name=exp_name,\n",
    "    notes=\"UNet flow model for directional diffusion from T1 to T2. 50 epochs.\",\n",
    "    n_epochs=150, \n",
    "    lr=1e-4,\n",
    "    generation_steps=300)\n",
    "\n",
    "generate_and_save_predictions(model, test_loader, device, output_dir=f'{OUTPUT_DIR}/{exp_name}')\n",
    "out_dataset = PredictionDataset(directory=f'{OUTPUT_DIR}/{exp_name}')\n",
    "with wandb.init(\n",
    "    project = 'flowmatching-t1-to-t2',\n",
    "    name=f'evaluation-{exp_name}',\n",
    "    notes=\"Evaluation of the flow model on the test set.\",\n",
    "):\n",
    "    summary = compute_ssim_from_dataset(out_dataset)\n",
    "    wandb.log({\"eval/metrics\": wandb.Table(dataframe=summary)})\n",
    "    wandb.log({\"eval/ssim_mean\": summary[\"Mean\"][0]})\n",
    "    wandb.log({\"eval/mse_mean\": summary[\"Mean\"][1]})\n",
    "    wandb.log({\"eval/ssim_var\": summary[\"Variance\"][0]})\n",
    "    wandb.log({\"eval/mse_var\": summary[\"Variance\"][1]})\n",
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2896b990",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load the best checkpoint\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# model.to(device)\n",
    "# checkpoint_path = f'{CHECKPOINTS_PATH}/checkpoint_unetflow-t1t2-150e_149.pth'\n",
    "# model.load_state_dict(torch.load(checkpoint_path, map_location=device)['model_state_dict'])\n",
    "# model.eval()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "medical (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
